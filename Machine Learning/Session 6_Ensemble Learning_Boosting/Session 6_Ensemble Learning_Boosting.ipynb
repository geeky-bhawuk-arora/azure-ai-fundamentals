{"cells":[{"cell_type":"markdown","metadata":{"id":"NT8_xxcTdZiU"},"source":["# Boosting\n","\n","Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors. In boosting, a random sample of data is selected, fitted with a model and then trained sequentially—that is, each model tries to compensate for the weaknesses of its predecessor. With each iteration, the weak rules from each individual classifier are combined to form one, strong prediction rule. \n","\n","<center><img src='https://i.imgur.com/Nndl37F.png'></center>\n","\n","## How Boosting Works?\n","\n","1. Samples generated from the training set are assigned the same weight to start with. These samples are used to train a homogeneous weak learner or base model.\n","\n","2. The prediction error for a sample is calculated – the greater the error, the weight of the sample increases. Hence, the sample becomes more important for training the next base model.\n","\n","3. The individual learner is weighted too – does well on its predictions, gets a higher weight assigned to it. So, a model that outputs good predictions will have a higher say in the final decision.\n","\n","4. The weighted data is then passed on to the following base model, and steps 2) and 3) are repeated until the data is fitted well enough to reduce the error below a certain threshold.\n","\n","5. When new data is fed into the boosting model, it is passed through all individual base models, and each model makes its own weighted prediction.\n","\n","6. Weight of these models is used to generate the final prediction. The predictions are scaled and aggregated to produce a final prediction."]},{"cell_type":"markdown","metadata":{"id":"iwnWaDUZ6l79"},"source":["<center> <img src='https://i.imgur.com/9uoELsY.jpg'></center>\n","<table>\n","<caption>Bagging Vs Boosting</caption> \n","<tr>\n","<th>Bagging</th> \t\n","<th>Boosting</th>\n","</tr>\n","\n","<tr>\n","<td>Various training data subsets are randomly drawn with replacement from the whole training dataset</td>\n","<td>Each new subset contains the components that were misclassified by previous models.</td>\n","</tr>\n","\n","<tr>\n","<td>Bagging attempts to tackle the over-fitting issue.</td>\n","<td>Boosting tries to reduce bias.</td>\n","</tr>\n","\n","<tr>\n","<td>If the classifier is unstable (high variance), then we need to apply bagging</td>\n","<td>If the classifier is steady and straightforward (high bias), then we need to apply boosting.</td>\n","</tr>\n","\n","<tr>\n","<td>Every model receives an equal weight.</td>\n","<td>Models are weighted by their performance.</td>\n","</tr>\n","\n","<tr> \t\n","<td>Objective to decrease variance, not bias.</td> \t\n","<td>Objective to decrease bias, not variance.</td>\n","</tr>\n","\n","<tr>\n","<td>It is the easiest way of connecting predictions that belong to the same type.</td> \t\n","<td>It is a way of connecting predictions that belong to the different types.\n","</td>\n","</tr> \t\n","<tr>\n","<td>Every model is constructed independently.</td>\n","<td>New models are affected by the performance of the previously developed model.</td>\n","<tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"O4FKB5m69eFB"},"source":["## Types of Boosting Algorithms\n","\n","Boosting algorithms can differ in how they create and aggregate weak learners during the sequential process. Three popular types of boosting methods include: \n","\n","- **Adaptive boosting or AdaBoost:** Yoav Freund and Robert Schapire are credited with the creation of the AdaBoost algorithm. This method operates iteratively, identifying misclassified data points and adjusting their weights to minimize the training error. The model continues optimize in a sequential fashion until it yields the strongest predictor.  \n","\n","- **Gradient boosting:** Building on the work of Leo Breiman, Jerome H. Friedman developed gradient boosting, which works by sequentially adding predictors to an ensemble with each one correcting for the errors of its predecessor. However, instead of changing weights of data points like AdaBoost, the gradient boosting trains on the residual errors of the previous predictor. The name, gradient boosting, is used since it combines the gradient descent algorithm and boosting method.  \n","\n","- **Extreme gradient boosting or XGBoost:** XGBoost is an implementation of gradient boosting that’s designed for computational speed and scale. XGBoost leverages multiple cores on the CPU, allowing for learning to occur in parallel during training.  \n"]},{"cell_type":"markdown","metadata":{"id":"zySI5o_79ygS"},"source":["### AdaBoost\n","\n","AdaBoost also called Adaptive Boosting is a technique in Machine Learning used as an Ensemble Method. The most common algorithm used with AdaBoost is decision trees with one level that means with Decision trees with only 1 split. These trees are also called **Decision Stumps.**\n","\n","<center><img src='https://i.imgur.com/0rDEc0l.png' ></center>\n","\n","Each instance in the training dataset is weighted. The initial weight is set to:\n","\n","$weight(x_i) = 1/n$\n","\n","Where $x_i$ is the $i^{th}$ training instance and n is the number of training instances.\n","\n","\n","What this algorithm does is that it builds a model and gives equal weights to all the data points. It then assigns higher weights to points that are wrongly classified. Now all the points which have higher weights are given more importance in the next model. It will keep training models until and unless a lower error is received.\n","<center><img src='https://i.imgur.com/81M84xY.png'></center>\n","\n","\n","### How To Train One Model\n","\n","A weak classifier (decision stump) is prepared on the training data using the weighted samples. Only binary (two-class) classification problems are supported, so each decision stump makes one decision on one input variable and outputs a **+1.0 or -1.0** value for the first or second class value.\n","\n","The misclassification rate is calculated for the trained model. Traditionally, this is calculated as:\n","\n","**error = (correct – N) / N**\n","\n","Where error is the misclassification rate, correct are the number of training instance predicted correctly by the model and N is the total number of training instances. For example, if the model predicted 78 of 100 training instances correctly the error or misclassification rate would be (78-100)/100 or 0.22.\n","\n","This is modified to use the weighting of the training instances:\n","\n","**error = sum(w(i) * t_error(i)) / sum(w)**\n","\n","Which is the weighted sum of the misclassification rate, \n","\n","where w is the weight for training instance i and \n","\n","t_error is the prediction error for training instance i which is **1 if misclassified and 0 if correctly classified.**\n","\n","**For example,** \n","\n","if we had 3 training instances with the weights 0.01, 0.5 and 0.2. \n","\n","The predicted values were -1, -1 and -1, and the actual output variables in the instances were -1, 1 and -1, then the terrors would be 0, 1, and 0. \n","\n","The misclassification rate would be calculated as:\n","\n","**error = (0.01x0 + 0.5x1 + 0.2x0) / (0.01 + 0.5 + 0.2)**\n","\n","or\n","\n","**error = 0.704**\n","\n","A stage value is calculated for the trained model which provides a weighting for any predictions that the model makes. \n","\n","The stage value for a trained model is calculated as follows:\n","\n","**stage = (1/2) *ln((1-error) / error)**\n","\n","Where stage is the stage value used to weight predictions from the model, ln() is the natural logarithm and error is the misclassification error for the model. The effect of the stage weight is that more accurate models have more weight or contribution to the final prediction.\n","\n","The training weights are updated giving more weight to incorrectly predicted instances, and less weight to correctly predicted instances.\n","\n","For example, the weight of one training instance (w) is updated using:\n","\n","**w = w * exp(stage * t_error)**\n","\n","Where \n","w is the weight for a specific training instance, \n","\n","exp() is the numerical constant e or Euler’s number raised to a power, \n","\n","stage is the misclassification rate for the weak classifier and \n","\n","t_error is the error the weak classifier made predicting the output variable for the training instance, evaluated as:\n","\n","**t_error = 0 if(y == p), otherwise 1**\n","\n","Where \n","\n","y is the output variable for the training instance and \n","\n","p is the prediction from the weak learner.\n","\n","This has the effect of not changing the weight if the training instance was classified correctly and making the weight slightly larger if the weak learner misclassified the instance.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"elapsed":682,"status":"ok","timestamp":1669128214411,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"hX8ApFV9dSXD","outputId":"c3549d7d-df1d-4641-dee3-c48983689b87"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RowNumber</th>\n","      <th>CustomerId</th>\n","      <th>Surname</th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>15634602</td>\n","      <td>Hargrave</td>\n","      <td>619</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>15647311</td>\n","      <td>Hill</td>\n","      <td>608</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>15619304</td>\n","      <td>Onio</td>\n","      <td>502</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>15701354</td>\n","      <td>Boni</td>\n","      <td>699</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>15737888</td>\n","      <td>Mitchell</td>\n","      <td>850</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n","0          1    15634602  Hargrave          619    France  Female   42   \n","1          2    15647311      Hill          608     Spain  Female   41   \n","2          3    15619304      Onio          502    France  Female   42   \n","3          4    15701354      Boni          699    France  Female   39   \n","4          5    15737888  Mitchell          850     Spain  Female   43   \n","\n","   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n","0       2       0.00              1          1               1   \n","1       1   83807.86              1          0               1   \n","2       8  159660.80              3          1               0   \n","3       1       0.00              2          0               0   \n","4       2  125510.82              1          1               1   \n","\n","   EstimatedSalary  Exited  \n","0        101348.88       1  \n","1        112542.58       0  \n","2        113931.57       1  \n","3         93826.63       0  \n","4         79084.10       0  "]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","train=pd.read_csv(\"Bank_churn.csv\")\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1669128214414,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"RbA6Yba8F8A9","outputId":"5a0160a0-fe29-4ee3-adda-a4e32ac22827"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-6be332e1-ade1-40b5-b534-1e195a780822\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RowNumber</th>\n","      <th>CustomerId</th>\n","      <th>Surname</th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>15634602</td>\n","      <td>Hargrave</td>\n","      <td>619</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>15647311</td>\n","      <td>Hill</td>\n","      <td>608</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>15619304</td>\n","      <td>Onio</td>\n","      <td>502</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>15701354</td>\n","      <td>Boni</td>\n","      <td>699</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>15737888</td>\n","      <td>Mitchell</td>\n","      <td>850</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6be332e1-ade1-40b5-b534-1e195a780822')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6be332e1-ade1-40b5-b534-1e195a780822 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6be332e1-ade1-40b5-b534-1e195a780822');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n","0          1    15634602  Hargrave          619    France  Female   42   \n","1          2    15647311      Hill          608     Spain  Female   41   \n","2          3    15619304      Onio          502    France  Female   42   \n","3          4    15701354      Boni          699    France  Female   39   \n","4          5    15737888  Mitchell          850     Spain  Female   43   \n","\n","   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n","0       2       0.00              1          1               1   \n","1       1   83807.86              1          0               1   \n","2       8  159660.80              3          1               0   \n","3       1       0.00              2          0               0   \n","4       2  125510.82              1          1               1   \n","\n","   EstimatedSalary  Exited  \n","0        101348.88       1  \n","1        112542.58       0  \n","2        113931.57       1  \n","3         93826.63       0  \n","4         79084.10       0  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1WlNouybwU8"},"outputs":[],"source":["# converting gender to 0 and 1 \n","# drop non numeric columns \n","\n","Gender=pd.get_dummies(train['Gender'],drop_first=True)\n","train=pd.concat([train,Gender], axis=1)\n","train.drop(['RowNumber','Surname','Geography','Gender'], axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1669128214418,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"vIIsjHmkb2-t","outputId":"2d389416-5b8e-47ca-90be-4b2398c3b6f4"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-690cd236-6f22-4da3-98f4-7bd706702771\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CustomerId</th>\n","      <th>CreditScore</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","      <th>Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15634602</td>\n","      <td>619</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>15647311</td>\n","      <td>608</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>15619304</td>\n","      <td>502</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>15701354</td>\n","      <td>699</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>15737888</td>\n","      <td>850</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-690cd236-6f22-4da3-98f4-7bd706702771')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-690cd236-6f22-4da3-98f4-7bd706702771 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-690cd236-6f22-4da3-98f4-7bd706702771');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   CustomerId  CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n","0    15634602          619   42       2       0.00              1          1   \n","1    15647311          608   41       1   83807.86              1          0   \n","2    15619304          502   42       8  159660.80              3          1   \n","3    15701354          699   39       1       0.00              2          0   \n","4    15737888          850   43       2  125510.82              1          1   \n","\n","   IsActiveMember  EstimatedSalary  Exited  Male  \n","0               1        101348.88       1     0  \n","1               1        112542.58       0     0  \n","2               0        113931.57       1     0  \n","3               0         93826.63       0     0  \n","4               1         79084.10       0     0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYU0Y5-Vb5lK"},"outputs":[],"source":["# split data into train and test dataset\n","X_train, X_test, y_train, y_test = train_test_split(train.drop('Exited',axis=1), \n","                                                    train['Exited'], test_size=0.2, \n","                                                    random_state=101)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":750,"status":"ok","timestamp":1669128215134,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"uqPPHw7Nb_jM","outputId":"bb26a4c9-d011-4d8f-a65f-103e4788a28b"},"outputs":[{"data":{"text/plain":["AdaBoostClassifier(random_state=1)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","\n","model = AdaBoostClassifier(random_state=1)\n","\n","model.fit(X_train,y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pqW2HjB5cJie"},"outputs":[],"source":["pred_1 = model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1669128215136,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"K3ZSAWk4cM6I","outputId":"d0a658f2-b97a-47ec-f588-07e0243058eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8535\n"]}],"source":["print(accuracy_score(pred_1,y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1669128215138,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"2ywwbjiNcP3B","outputId":"0fa663cc-883e-49bf-9744-6cea6741e331"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.95      0.87      0.91      1724\n","           1       0.48      0.74      0.58       276\n","\n","    accuracy                           0.85      2000\n","   macro avg       0.72      0.80      0.75      2000\n","weighted avg       0.89      0.85      0.87      2000\n","\n"]}],"source":["print(classification_report(pred_1,y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":933,"status":"ok","timestamp":1669128216058,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"OlXRBUD9cSiq","outputId":"bbfc703a-202b-4473-a3ad-c3f04d2f135f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score 0.8545\n","\n","classification report:\n","\t               precision    recall  f1-score   support\n","\n","           0       0.96      0.87      0.91      1730\n","           1       0.48      0.74      0.58       270\n","\n","    accuracy                           0.85      2000\n","   macro avg       0.72      0.81      0.75      2000\n","weighted avg       0.89      0.85      0.87      2000\n","\n"]}],"source":["# Adaboost with Decision Tree Classifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","dt_classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1,\n","                                                      max_features=4,\n","                                                      min_samples_leaf=20),\n","                                n_estimators=200)\n","\n","\n","dt_classifier.fit(X_train,y_train)\n","\n","\n","pred_2 = dt_classifier.predict(X_test)\n","\n","print('Accuracy Score',accuracy_score(pred_2,y_test))\n","\n","print()\n","\n","print('classification report:\\n\\t',classification_report(pred_2,y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11885,"status":"ok","timestamp":1669128227939,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"b2Abzecsc4q-","outputId":"bef26ae6-b80d-47a5-df98-24ecbc912263"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score 0.7885\n","\n","classification report:\n","\t               precision    recall  f1-score   support\n","\n","           0       1.00      0.79      0.88      2000\n","           1       0.00      0.00      0.00         0\n","\n","    accuracy                           0.79      2000\n","   macro avg       0.50      0.39      0.44      2000\n","weighted avg       1.00      0.79      0.88      2000\n","\n"]}],"source":["# Adaboost with Logistic Regression\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","lr_classifier = AdaBoostClassifier(base_estimator=LogisticRegression(),\n","                                n_estimators=200,learning_rate=0.001)\n","\n","\n","lr_classifier.fit(X_train,y_train)\n","\n","\n","pred_3 = lr_classifier.predict(X_test)\n","\n","print('Accuracy Score',accuracy_score(pred_3,y_test))\n","\n","print()\n","\n","print('classification report:\\n\\t',classification_report(pred_3,y_test))"]},{"cell_type":"markdown","metadata":{"id":"DZtPs9OogZaK"},"source":["### Gradient Boosting Tree\n","\n","In Machine Learning, we use gradient boosting to solve classification and regression problems. It is a sequential ensemble learning technique where the performance of the model improves over iterations. \n","\n","This method creates the model in a stage-wise fashion. It infers the model by enabling the optimization of an absolute differentiable loss function. As we add each weak learner, a new model is created that gives a more precise estimation of the response variable.\n","\n","The gradient boosting algorithm requires the below components to function:\n","\n","1. **Loss function:** To reduce errors in prediction, we need to optimize the loss function. Unlike in AdaBoost, the incorrect result is not given a higher weightage in gradient boosting. It tries to reduce the loss function by averaging the outputs from weak learners.\n","\n","2. **Weak learner:** In gradient boosting, we require weak learners to make predictions. To get real values as output, we use regression trees. To get the most suitable split point, we create trees in a greedy manner, due to this the model overfits the dataset.\n","\n","3. **Additive model:** In gradient boosting, we try to reduce the loss by adding decision trees. Also, we can minimize the error rate by cutting down the parameters. So, in this case, we design the model in such a way that the addition of a tree does not change the existing tree.\n","\n","Finally, we update the weights to minimize the error that is being calculated.\n","\n","\n","\n","\n","**The Algorithm:**\n","\n","- Calculate the average of the label column as initially this average shall minimise the total error.\n","- Calculate the pseudo residuals.\n","\n","$Pseudo__residual= actual label - the predicted result (which is average in the first iteration)$\n","\n","  Mathematically,\n","  \n","derivative of the pseudo residual=$(\\frac {\\delta L(y_i,f(x_i))}{\\delta (f(x_i))})$\n","     \n","where, L is the loss function.\n","                          \n","               \n","Here, the gradient of the error term is getting calculated as the goal is to minimize the error. Hence the name gradient boosted trees\n","- create a tree to predict the pseudo residuals instead  of a tree to predict for the actual column values.\n","- new result= previous result+learning rate* residual \n","   \n","   Mathematically, \n","     $ F_1(x)= F_0(x)+ \\nu \\sum \\gamma $\n","     \n"," where  $ \\nu $ is the learning rate and $ \\gamma $ is the residual\n","\n","Repeat these steps until the residual stops decreasing\n","\n","\n","# [For More info Click Here 👈](https://xgboost.readthedocs.io/en/stable/tutorials/model.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XljE2dioAXsH"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","url='https://raw.githubusercontent.com/ubaid-shah/datasets/main/Bank_churn.csv'\n","train=pd.read_csv(url)\n","\n","\n","# converting gender to 0 and 1 \n","# drop non numeric columns \n","\n","Gender=pd.get_dummies(train['Gender'],drop_first=True)\n","train=pd.concat([train,Gender], axis=1)\n","train.drop(['RowNumber','Surname','Geography','Gender'], axis=1, inplace=True)\n","\n","# split data into train and test dataset\n","X_train, X_test, y_train, y_test = train_test_split(train.drop('Exited',axis=1), \n","                                                    train['Exited'], test_size=0.2, \n","                                                    random_state=101)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":721,"status":"ok","timestamp":1669182163733,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"zdYirgjwn4ve","outputId":"faa726b9-d317-4bee-e041-f15e0c366c1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Scikit-learn GBM Log-Loss:0.426210640854544\n"]}],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import log_loss\n","\n","sklearn_gbm = GradientBoostingClassifier(\n","    n_estimators=20, \n","    learning_rate=0.1, \n","    max_depth=1\n",")\n","sklearn_gbm.fit(X_train, y_train)\n","sklearn_gbm_log_loss = log_loss(y_test, sklearn_gbm.predict_proba(X_test))\n","print(f\"Scikit-learn GBM Log-Loss:{sklearn_gbm_log_loss:.15f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1669182169283,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"jFfg48ymrVr8","outputId":"486141fa-fbc7-455b-eff7-36d89e6d2d29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score 0.8065\n","\n","classification report:\n","\t               precision    recall  f1-score   support\n","\n","           0       1.00      0.80      0.89      1960\n","           1       0.09      0.95      0.16        40\n","\n","    accuracy                           0.81      2000\n","   macro avg       0.54      0.88      0.53      2000\n","weighted avg       0.98      0.81      0.88      2000\n","\n"]}],"source":["pred_4 = sklearn_gbm.predict(X_test)\n","\n","print('Accuracy Score',accuracy_score(pred_4,y_test))\n","\n","print()\n","\n","print('classification report:\\n\\t',classification_report(pred_4,y_test))"]},{"cell_type":"markdown","metadata":{"id":"DOw7MlnjvKFj"},"source":["### XGBoost\n","\n","XGBoost stands for eXtreme Gradient Boosting.\n","\n","When it comes to a superfast machine learning algorithm that works on tree-based models and tries to reach the best in class accuracy by optimally using computational resources, XGBoost or Extreme Gradient Boosting becomes the most natural choice. Created by Tianqi Chen, the XGBoost algorithm has recently got so much popularity owing to its massive usage in most of the hackathons and Kaggle competitions. \n","\n","![](https://i.imgur.com/mSAEqqm.png)\n","\n","In simple terms, XGBoost may be formally defined as a decision tree-based ensemble learning framework that uses Gradient Descent as the underlying objective function and comes with a lot of flexibility while delivering the desired results by optimally using computational power. \n","\n","## What Algorithm Does XGBoost Use?\n","\n","The XGBoost library implements the gradient boosting decision tree algorithm.\n","\n","This algorithm goes by lots of different names such as gradient boosting, multiple additive regression trees, stochastic gradient boosting or gradient boosting machines.\n","\n","Boosting is an ensemble technique where new models are added to correct the errors made by existing models. Models are added sequentially until no further improvements can be made. A popular example is the AdaBoost algorithm that weights data points that are hard to predict.\n","\n","Gradient boosting is an approach where new models are created that predict the residuals or errors of prior models and then added together to make the final prediction. It is called gradient boosting because it uses a gradient descent algorithm to minimize the loss when adding new models.\n","\n","This approach supports both regression and classification predictive modeling problems.\n","\n","##  Unique features of XGBoost:\n","\n","XGBoost is a popular implementation of gradient boosting. Let’s discuss some features of XGBoost that make it so interesting.\n"," \n","**Regularisation:**\n","\n","XGBoost has an option to penalise complex models through both L1 and L2 regularisation. Regularisation helps in preventing overfitting.\n","\n","**Handling sparse data:** \n","\n","Missing values or data processing steps like one-hot encoding make data sparse. XGBoost incorporates a sparsity-aware split finding algorithm to handle different types of sparsity patterns in the data.\n","\n","**Weighted quantile sketch:**\n","\n","Most existing tree based algorithms can find the split points when the data points are equal weights (using a quantile sketch algorithm). However, they are not equipped to handle weighted data. XGBoost has a distributed weighted quantile sketch algorithm to handle weighted data effectively.\n","\n","**Block structure for parallel learning:**\n","\n","For faster computing, XGBoost can use multiple cores on the CPU. This is possible because of a block structure in its system design. Data is sorted and stored in in-memory units called blocks. Unlike other algorithms, this enables the data layout to be reused by subsequent iterations instead of computing it again. This feature also serves useful for steps like split finding and column sub-sampling.\n","\n","**Cache awareness:**\n","\n","In the XGBoost classifier algorithm, non-continuous memory access is required to get the gradient statistics by row index. Hence, XGBoost has been designed to make optimal use of hardware. This is done by allocating internal buffers in each thread, where the gradient statistics can be stored.\n","\n","**Out-of-core computing:** \n","\n","This feature optimises the available disk space and maximises its usage when handling huge datasets that do not fit into memory.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6345,"status":"ok","timestamp":1669128235448,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"yPJMk21uyspa","outputId":"2597f241-adeb-43ad-8edb-af7c70bfb4f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n"]}],"source":["!pip install xgboost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fXHwicIAuKT"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","url='https://raw.githubusercontent.com/ubaid-shah/datasets/main/Bank_churn.csv'\n","train=pd.read_csv(url)\n","\n","\n","# converting gender to 0 and 1 \n","# drop non numeric columns \n","\n","Gender=pd.get_dummies(train['Gender'],drop_first=True)\n","train=pd.concat([train,Gender], axis=1)\n","train.drop(['RowNumber','Surname','Geography','Gender'], axis=1, inplace=True)\n","\n","# split data into train and test dataset\n","X_train, X_test, y_train, y_test = train_test_split(train.drop('Exited',axis=1), \n","                                                    train['Exited'], test_size=0.2, \n","                                                    random_state=101)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1268,"status":"ok","timestamp":1669182212917,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"h0G5MX-FxMkE","outputId":"3bbc7e7e-0a25-41fc-ef9e-b24cb7523e12"},"outputs":[{"data":{"text/plain":["XGBClassifier(learning_rate=0.01, random_state=1)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import xgboost as xgb\n","xg_model = xgb.XGBClassifier(random_state=1,\n","                             learning_rate=0.01)\n","xg_model.fit(X_train,y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Buu7FBLuxyul"},"outputs":[],"source":["pred_5 = xg_model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1669128237787,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"1IwttEi9x5rX","outputId":"236e2aab-00be-4f70-8d9c-4600002c2f59"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.857\n"]}],"source":["print(accuracy_score(pred_5,y_test))"]},{"cell_type":"markdown","metadata":{"id":"iFhHKKBVFCOq"},"source":["With more number of Hyper parameters\n","\n","[For more details click here 👈](https://xgboost.readthedocs.io/en/stable/parameter.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NajPg5GJx8td"},"outputs":[],"source":["new_xbg_model = xgb.XGBClassifier(base_score=0.2, booster='gbtree', colsample_bylevel=0.5,\n","                              colsample_bynode=0.5, colsample_bytree=0.5, gamma=0, gpu_id=0,\n","                              importance_type='gain', interaction_constraints='',\n","                              learning_rate=0.05, max_delta_step=0, max_depth=3,\n","                              min_child_weight=1, monotone_constraints='(1,0)',\n","                              n_estimators=1000, n_jobs=0, num_parallel_tree=1,\n","                              objective='binary:logistic', random_state=211, reg_alpha=0,\n","                              reg_lambda=1, scale_pos_weight=1, subsample=1,\n","                              tree_method='exact', validate_parameters=1, verbosity=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":847,"status":"ok","timestamp":1669183095425,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"s_D2mXf_yBSo","outputId":"ad125b43-5c9a-44be-ca1a-53efb018a5ca"},"outputs":[{"data":{"text/plain":["XGBClassifier(base_score=0.2, colsample_bylevel=0.5, colsample_bynode=0.5,\n","              colsample_bytree=0.5, gpu_id=0, interaction_constraints='',\n","              learning_rate=0.05, monotone_constraints='(1,0)',\n","              n_estimators=1000, n_jobs=0, num_parallel_tree=1,\n","              random_state=211, tree_method='exact', validate_parameters=1,\n","              verbosity=0)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["new_xbg_model.fit(X_train,y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669183303755,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"I8tZ0azmyEc4","outputId":"7e824c5a-fa16-4e05-8c91-ec5e1170266d"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.857\n"]}],"source":["pred_6 = xg_model.predict(X_test)\n","print(accuracy_score(pred_6,y_test))"]},{"cell_type":"markdown","metadata":{"id":"THtAGroBGTPN"},"source":["## Voting Classifier\n","\n","A Voting Classifier is a machine learning model that trains on an ensemble of numerous models and predicts an output (class) based on their highest probability of chosen class as the output.\n","\n","![](https://i.imgur.com/21CKPuJ.jpg)\n","\n","It simply aggregates the findings of each classifier passed into Voting Classifier and predicts the output class based on the highest majority of voting. The idea is instead of creating separate dedicated models and finding the accuracy for each them, we create a single model which trains by these models and predicts output based on their combined majority of voting for each output class.\n","\n","Voting Classifier supports two types of votings.\n","\n","- **Hard Voting:** In hard voting, the predicted output class is a class with the highest majority of votes i.e the class which had the highest probability of being predicted by each of the classifiers. Suppose three classifiers predicted the output class(A, A, B), so here the majority predicted A as output. Hence A will be the final prediction.\n","- **Soft Voting:** In soft voting, the output class is the prediction based on the average of probability given to that class. Suppose given some input to three models, the prediction probability for class A = (0.30, 0.47, 0.53) and B = (0.20, 0.32, 0.40). So the average for class A is 0.4333 and B is 0.3067, the winner is clearly class A because it had the highest probability averaged by each classifier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BfoGT3pE-jI"},"outputs":[],"source":["# importing libraries\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","\n","url='https://raw.githubusercontent.com/ubaid-shah/datasets/main/Bank_churn.csv'\n","train=pd.read_csv(url)\n","\n","\n","# converting gender to 0 and 1 \n","# drop non numeric columns \n","\n","Gender=pd.get_dummies(train['Gender'],drop_first=True)\n","train=pd.concat([train,Gender], axis=1)\n","train.drop(['RowNumber','Surname','Geography','Gender'], axis=1, inplace=True)\n","\n","# split data into train and test dataset\n","X_train, X_test, y_train, y_test = train_test_split(train.drop('Exited',axis=1), \n","                                                    train['Exited'], test_size=0.2, \n","                                                    random_state=101)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dslxyzyqH-mt"},"outputs":[],"source":["# group / ensemble of models\n","estimator = []\n","estimator.append(('LR',\n","\t\t\t\tLogisticRegression()))\n","\n","estimator.append(('DTC', DecisionTreeClassifier()))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cEFG0oUWIMao"},"outputs":[],"source":["# Voting Classifier with hard voting\n","vot_hard = VotingClassifier(estimators = estimator, voting ='hard')\n","vot_hard.fit(X_train, y_train)\n","y_pred = vot_hard.predict(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669184708882,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"SdD7zguXIPuA","outputId":"497d2208-7527-499d-d6d7-86c69553c24d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Hard Voting Score 0.7885\n"]}],"source":["# using accuracy_score metric to predict accuracy\n","score = accuracy_score(y_test, y_pred)\n","print(\"Hard Voting Score %.4f\" % score)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1039,"status":"ok","timestamp":1669184715193,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"N8tHwYyLIS8J","outputId":"b590f5f2-47a5-4b75-d36c-3483bad79fef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Soft Voting Score 0.7870\n"]}],"source":["# Voting Classifier with soft voting\n","vot_soft = VotingClassifier(estimators = estimator, voting ='soft')\n","vot_soft.fit(X_train, y_train)\n","y_pred = vot_soft.predict(X_test)\n","\n","# using accuracy_score\n","score = accuracy_score(y_test, y_pred)\n","print(\"Soft Voting Score %.4f\" % score)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":850,"status":"ok","timestamp":1669184721431,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"eUVvBZKXIUTA","outputId":"d845ea14-f270-459d-c655-c69880d91fb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["LogisticRegression: 0.7885\n","DecisionTreeClassifier: 0.7885\n"]}],"source":["lr = LogisticRegression()\n","DT =DecisionTreeClassifier()\n","\n","models = [lr, DT]\n","\n","for model in models:\n","    model.fit(X_train, y_train)\n","    predicted = model.predict(X_test)\n","    accuracy = accuracy_score(predicted, y_test)\n","    model_name = model.__class__.__name__\n","    print(f'{model_name}: {accuracy:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"hNTNstYnLORG"},"source":["## Voting Regressor\n","\n","A voting regressor is an ensemble meta-estimator that fits several base regressors, each on the whole dataset. Then it averages the individual predictions to form a final prediction. We will use three different regressors to predict the data: GradientBoostingRegressor, RandomForestRegressor, and LinearRegression). Then the above 3 regressors will be used for the VotingRegressor.\n","\n","Finally, we will plot the predictions made by all models for comparison.\n","\n","We will work with the diabetes dataset which consists of 10 features collected from a cohort of diabetes patients. The target is a quantitative measure of disease progression one year after baseline."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsE_Be2WL6TW"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","from sklearn.datasets import load_diabetes\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import VotingRegressor\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fJ-my6qhMBob"},"source":["First, we will load the diabetes dataset and initiate a gradient boosting regressor, a random forest regressor and a linear regression. Next, we will use the 3 regressors to build the voting regressor:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1203,"status":"ok","timestamp":1669185164269,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"QxDe9yrEMAqR","outputId":"9ea80e17-c6ce-4757-bdfb-6340ec43b763"},"outputs":[{"data":{"text/plain":["VotingRegressor(estimators=[('gb', GradientBoostingRegressor(random_state=1)),\n","                            ('rf', RandomForestRegressor(random_state=1)),\n","                            ('lr', LinearRegression())])"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["X, y = load_diabetes(return_X_y=True)\n","\n","# Train classifiers\n","reg1 = GradientBoostingRegressor(random_state=1)\n","reg2 = RandomForestRegressor(random_state=1)\n","reg3 = LinearRegression()\n","\n","reg1.fit(X, y)\n","reg2.fit(X, y)\n","reg3.fit(X, y)\n","\n","ereg = VotingRegressor([(\"gb\", reg1), (\"rf\", reg2), (\"lr\", reg3)])\n","ereg.fit(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EFx_wFAkMEbA"},"outputs":[],"source":["# Now we will use each of the regressors to make the 20 first predictions.\n","\n","xt = X[:20]\n","\n","pred1 = reg1.predict(xt)\n","pred2 = reg2.predict(xt)\n","pred3 = reg3.predict(xt)\n","pred4 = ereg.predict(xt)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1669185226853,"user":{"displayName":"Ubaid Shah (Ghazal)","userId":"14042789612785146189"},"user_tz":-330},"id":"NpngS26qMKfS","outputId":"6e2c2d75-159a-48bb-872b-7ab9347f6cf0"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 720x576 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Finally, we will visualize the 20 predictions. The red stars show the average prediction made by VotingRegressor.\n","\n","plt.figure(figsize=(10,8))\n","plt.plot(pred1, \"gd\", label=\"GradientBoostingRegressor\")\n","plt.plot(pred2, \"b^\", label=\"RandomForestRegressor\")\n","plt.plot(pred3, \"ys\", label=\"LinearRegression\")\n","plt.plot(pred4, \"r*\", ms=10, label=\"VotingRegressor\")\n","\n","plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n","plt.ylabel(\"predicted\")\n","plt.xlabel(\"training samples\")\n","plt.legend(loc=\"best\")\n","plt.title(\"Regressor predictions and their average\")\n","\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTyRXWy3MPBq"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO3bG+wFnRaTj4e/UWPbrS+","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
