{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import software libraries and load the dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys                             # Read system parameters.\n",
    "import numpy as np                     # Work with multi-dimensional arrays and matrices.\n",
    "from numpy.random import seed\n",
    "import pandas as pd                    # Manipulate and analyze data frames.\n",
    "import sklearn                         # Perform feature engineering and machine learning.\n",
    "import tensorflow                      # Train neural networks for deep learning.\n",
    "import keras                           # Provide a frontend for TensorFlow.\n",
    "from keras import datasets\n",
    "import matplotlib                      # Create charts.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb                   # Streamline charting.\n",
    "\n",
    "# Summarize software libraries used.\n",
    "print('Libraries used in this project:')\n",
    "print('- NumPy {}'.format(np.__version__))\n",
    "print('- pandas {}'.format(pd.__version__))\n",
    "print('- scikit-learn {}'.format(sklearn.__version__))\n",
    "print('- TensorFlow {}'.format(tensorflow.__version__))\n",
    "print('- Keras {}'.format(keras.__version__))\n",
    "print('- Matplotlib {}'.format(matplotlib.__version__))\n",
    "print('- Seaborn {}'.format(sb.__version__))\n",
    "print('- Python {}\\n'.format(sys.version))\n",
    "\n",
    "# Load the dataset.\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "print('Loaded {} training records.'.format(len(X_train.data)))\n",
    "print('Loaded {} testing records.'.format(len(X_test.data)))\n",
    "\n",
    "# Comment the following two lines to make outcomes stochastic, or supply different seed values.\n",
    "seed(10)\n",
    "tensorflow.random.set_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get acquainted with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dimensions of the training and testing sets and their labels.\n",
    "print('Shape of data used for training and testing:\\n')\n",
    "print('Training data:   {}'.format(X_train.shape))\n",
    "print('Training labels: {}\\n'.format(y_train.shape))\n",
    "print('Testing data:    {}'.format(X_test.shape))\n",
    "print('Testing labels:  {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show a preview of the first 20 images in a subplot grid.\n",
    "# Include the class label for each one.\n",
    "fig, axes = plt.subplots(nrows = 4, ncols = 5, figsize = (10, 10))\n",
    "\n",
    "for i, ax in zip(range(25), axes.flatten()):\n",
    "    ax.imshow(X_train[i,:,:], cmap = 'gray')  # Use a grayscale color map.\n",
    "    ax.title.set_text('Class: {}'.format(y_train[i]))\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for training with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape arrays to add grayscale flag.\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# One-hot encode the data for each label.\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Print the one-hot encoding for the first image.\n",
    "print('One-hot encoding for first image: {}'.format(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training and validation datasets and their labels.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                  y_train,\n",
    "                                                  random_state = 50)\n",
    "\n",
    "# Print shape of training and validation sets.\n",
    "print(f'Training features:         {X_train.shape}')\n",
    "print(f'Validation features:       {X_val.shape}')\n",
    "print(f'Training labels:           {y_train.shape}')\n",
    "print(f'Validation labels:         {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the CNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "# Create the model.\n",
    "cnn = Sequential()\n",
    "\n",
    "# Add model layers as specified.\n",
    "cnn.add(Conv2D(64, kernel_size = 3, activation = 'relu', input_shape = (28, 28, 1)))\n",
    "cnn.add(Conv2D(32, kernel_size = 3, activation = 'relu'))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model and summarize the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "cnn.compile(optimizer = 'adam',\n",
    "            loss = 'categorical_crossentropy',\n",
    "            metrics = ['accuracy'])\n",
    "\n",
    "# Summarize the layers.\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a graph of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a graph of the model.\n",
    "from keras.utils import plot_model\n",
    "plot_model(cnn, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model over 1 epoch.\n",
    "cnn_trained = cnn.fit(X_train, y_train,\n",
    "                      validation_data = (X_val, y_val),\n",
    "                      epochs = 1,\n",
    "                      verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data, showing loss and accuracy.\n",
    "eval_test = cnn.evaluate(X_test, y_test, verbose = 0)\n",
    "\n",
    "print('Loss: {}'.format(round(eval_test[0], 2)))\n",
    "print('Accuracy: {:.0f}%'.format(eval_test[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data.\n",
    "prediction = cnn.predict(X_test)\n",
    "prediction = np.argmax(np.round(prediction), axis = 1)  # Extract class number from one-hot-encoded array.\n",
    "actual = np.argmax(np.round(y_test), axis = 1)\n",
    "\n",
    "# Print the first 20 example predictions.\n",
    "print('First 20 example predictions:')\n",
    "print('Actual class:    {}'.format(actual[:30]))\n",
    "print('Predicted class: {}'.format(prediction[:30]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the predictions for 20 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using the test set, show the first 20 predictions, highlighting any incorrect predictions in color.\n",
    "fig, axes = plt.subplots(nrows = 4, ncols = 5, figsize = (10, 10))\n",
    "\n",
    "for i, ax in zip(range(20), axes.flatten()):\n",
    "    if actual[i] == prediction[i]:\n",
    "        ax.imshow(X_test[i].reshape(28, 28), cmap = 'gray')\n",
    "    else:\n",
    "        ax.imshow(X_test[i].reshape(28, 28))\n",
    "        \n",
    "    ax.title.set_text('Actual: {}\\nPredicted: {}'.format(actual[i], prediction[i]))\n",
    "    \n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
